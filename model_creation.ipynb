{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 02:04:14.317393: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-02 02:04:14.538960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746122654.639953   15459 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746122654.667513   15459 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746122654.859361   15459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746122654.859387   15459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746122654.859389   15459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746122654.859389   15459 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-02 02:04:14.884760: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "import h5py\n",
    "import numpy as np\n",
    "import chowdhury_s_model_builder\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.api.models import Sequential, Model, load_model\n",
    "from keras.api.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, LSTM, Input, GlobalAveragePooling2D\n",
    "from keras.api.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.api.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.api import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 256, 1292) float32\n",
      "(5000, 7) int8\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(\"Data/Mid-Level_Perceptual_Features_Data.h5\", \"r\") as hf:\n",
    "    mid_level_train_data = hf[\"train\"][:]  # Load the train dataset\n",
    "    mid_level_label_data = hf[\"label\"][:]  # Load the label dataset\n",
    "\n",
    "print(mid_level_train_data.shape, mid_level_train_data.dtype)  # Check the shape and type\n",
    "print(mid_level_label_data.shape, mid_level_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melodiousness: 1340\n",
      "Articulation: 907\n",
      "Rhythmic Complexity: 295\n",
      "Rhythmic Stability: 1540\n",
      "Dissonance: 440\n",
      "Tonal Stability: 2375\n",
      "Modality: 813\n"
     ]
    }
   ],
   "source": [
    "label_counts = np.sum(mid_level_label_data, axis=0)\n",
    "\n",
    "# Optional: class names if you have them\n",
    "class_names = [\"Melodiousness\", \"Articulation\", \"Rhythmic Complexity\", \"Rhythmic Stability\",  \"Dissonance\", \"Tonal Stability\", \"Modality\"]\n",
    "\n",
    "for i, count in enumerate(label_counts):\n",
    "    print(f\"{class_names[i] if i < len(class_names) else 'Class ' + str(i)}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 256, 1292) float32\n",
      "(400, 7) int8\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(\"Data/Emotify_Annotated_Data.h5\", \"r\") as hf:\n",
    "    emotify_train_data = hf[\"train\"][:]  # Load the train dataset\n",
    "    emotify_label_data = hf[\"label\"][:]  # Load the label dataset\n",
    "\n",
    "print(emotify_train_data.shape, emotify_train_data.dtype)  # Check the shape and type\n",
    "print(emotify_label_data.shape, emotify_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melodiousness: 103\n",
      "Articulation: 88\n",
      "Rhythmic Complexity: 19\n",
      "Rhythmic Stability: 81\n",
      "Dissonance: 27\n",
      "Tonal Stability: 208\n",
      "Modality: 67\n"
     ]
    }
   ],
   "source": [
    "label_counts = np.sum(emotify_label_data, axis=0)\n",
    "\n",
    "# Optional: class names if you have them\n",
    "class_names = [\"Melodiousness\", \"Articulation\", \"Rhythmic Complexity\", \"Rhythmic Stability\",  \"Dissonance\", \"Tonal Stability\", \"Modality\"]\n",
    "\n",
    "for i, count in enumerate(label_counts):\n",
    "    print(f\"{class_names[i] if i < len(class_names) else 'Class ' + str(i)}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = np.concatenate([mid_level_train_data, emotify_train_data], axis=0)\n",
    "combined_label = np.concatenate([mid_level_label_data, emotify_label_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "permutation = np.random.permutation(combined_train.shape[0]) # Randomly permute the indices using \"5000 + 400\"\n",
    "shuffled_train = combined_train[permutation]\n",
    "shuffled_label = combined_label[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled Train Shape: (5400, 256, 1292)\n",
      "Shuffled Label Shape: (5400, 7)\n"
     ]
    }
   ],
   "source": [
    "# Print final shapes to verify\n",
    "print(\"Shuffled Train Shape:\", shuffled_train.shape)\n",
    "print(\"Shuffled Label Shape:\", shuffled_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melodiousness: 1443\n",
      "Articulation: 995\n",
      "Rhythmic Complexity: 314\n",
      "Rhythmic Stability: 1621\n",
      "Dissonance: 467\n",
      "Tonal Stability: 2583\n",
      "Modality: 880\n"
     ]
    }
   ],
   "source": [
    "label_counts = np.sum(shuffled_label, axis=0)\n",
    "\n",
    "# Optional: class names if you have them\n",
    "class_names = [\"Melodiousness\", \"Articulation\", \"Rhythmic Complexity\", \"Rhythmic Stability\",  \"Dissonance\", \"Tonal Stability\", \"Modality\"]\n",
    "\n",
    "for i, count in enumerate(label_counts):\n",
    "    print(f\"{class_names[i] if i < len(class_names) else 'Class ' + str(i)}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train = shuffled_train[..., np.newaxis]  # Add a new axis to the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled Train Shape: (5400, 256, 1292, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shuffled Train Shape:\", shuffled_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid_level_train_data = mid_level_train_data[..., np.newaxis]\n",
    "\n",
    "# print(mid_level_train_data.shape, mid_level_train_data.dtype)  # Check the shape and type\n",
    "# print(mid_level_label_data.shape, mid_level_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotify_train_data = emotify_train_data[..., np.newaxis]\n",
    "\n",
    "# print(emotify_train_data.shape, emotify_train_data.dtype)  # Check the shape and type\n",
    "# print(emotify_label_data.shape, emotify_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid_level_input_shape = mid_level_train_data.shape[1], mid_level_train_data.shape[2], mid_level_train_data.shape[3]\n",
    "# emotify_input_shape = emotify_train_data.shape[1], emotify_train_data.shape[2], emotify_train_data.shape[3]\n",
    "# print(mid_level_input_shape)\n",
    "# print(mid_level_input_shape, emotify_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tensorflow.device('/GPU:0'):\n",
    "#     input = Input(shape=(256, 1292, 1))\n",
    "#     x =  Conv2D(64, (5, 5), strides=2, activation=\"relu\", padding=\"valid\")(input)\n",
    "#     x =  BatchNormalization()(x)   \n",
    "#     # 2nd Layer\n",
    "#     x =  Conv2D(64, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 3rd Layer\n",
    "#     x =  MaxPooling2D((2, 2))(x)\n",
    "#     x =  Dropout(0.3)(x)    \n",
    "#     # 4th Layer\n",
    "#     x =  Conv2D(128, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 5th Layer\n",
    "#     x =  Conv2D(128, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 6th Layer\n",
    "#     x =  MaxPooling2D((2, 2))(x)\n",
    "#     x =  Dropout(0.3)(x)    \n",
    "#     # 7th Layer\n",
    "#     x =  Conv2D(256, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 8th Layer\n",
    "#     x =  Conv2D(256, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 9th Layer\n",
    "#     x =  Conv2D(384, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 10th Layer\n",
    "#     x =  Conv2D(512, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 11th Layer\n",
    "#     x =  Conv2D(256, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x) \n",
    "#     # 12th Layer\n",
    "#     # x = tfa.layers.AdaptiveAveragePooling2D(x)\n",
    "#     x =  GlobalAveragePooling2D(keepdims=True)(x)\n",
    "#     x =  Flatten()(x)\n",
    "#     x = keras.layers.Dense(256)(x)\n",
    "#     A2Mid2E_branch = keras.layers.Dense(7, activation=\"sigmoid\")(x)\n",
    "#     model = Model(inputs=input, outputs=A2Mid2E_branch, name=\"Mid-Level_Features\")\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746122856.286307   15459 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1746122856.291622   15459 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_epoch_52_acc_0.82_loss_0.02_valacc_0.91_valloss_0.02.keras\")\n",
    "# model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"checkpoint_epoch-{epoch:02d}_acc-{accuracy:.4f}_loss-{loss:.4f}.keras\",\n",
    "    monitor='accuracy',          # Monitor training accuracy\n",
    "    mode='max',                   # Save when training accuracy improves\n",
    "    save_best_only=True,          # Save only the best model\n",
    "    save_weights_only=False,      # Save the entire model\n",
    "    verbose=1\n",
    ")\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                           loss='binary_crossentropy', metrics=[\"accuracy\"]\n",
    "                           )\n",
    "model.fit(mid_level_train_data,\n",
    "          mid_level_label_data,\n",
    "          batch_size=8,\n",
    "          epochs=54,\n",
    "          initial_epoch=52,\n",
    "          callbacks=[checkpoint_callback],\n",
    "          shuffle=True, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
