{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "import h5py\n",
    "import numpy as np\n",
    "import chowdhury_s_model_builder\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.api.models import Sequential, Model, load_model\n",
    "from keras.api.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, LSTM, Input, GlobalAveragePooling2D\n",
    "from keras.api.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(\"Data/Mid-Level_Perceptual_Features_Data.h5\", \"r\") as hf:\n",
    "    mid_level_train_data = hf[\"train\"][:]  # Load the train dataset\n",
    "    mid_level_label_data = hf[\"label\"][:]  # Load the label dataset\n",
    "\n",
    "print(mid_level_train_data.shape, mid_level_train_data.dtype)  # Check the shape and type\n",
    "print(mid_level_label_data.shape, mid_level_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.sum(mid_level_label_data, axis=0)\n",
    "\n",
    "# Optional: class names if you have them\n",
    "class_names = [\"Melodiousness\", \"Articulation\", \"Rhythmic Complexity\", \"Rhythmic Stability\",  \"Dissonance\", \"Tonal Stability\", \"Modality\"]\n",
    "\n",
    "for i, count in enumerate(label_counts):\n",
    "    print(f\"{class_names[i] if i < len(class_names) else 'Class ' + str(i)}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(\"Data/Emotify_Annotated_Data.h5\", \"r\") as hf:\n",
    "    emotify_train_data = hf[\"train\"][:]  # Load the train dataset\n",
    "    emotify_label_data = hf[\"label\"][:]  # Load the label dataset\n",
    "\n",
    "print(emotify_train_data.shape, emotify_train_data.dtype)  # Check the shape and type\n",
    "print(emotify_label_data.shape, emotify_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.sum(emotify_label_data, axis=0)\n",
    "\n",
    "# Optional: class names if you have them\n",
    "class_names = [\"Melodiousness\", \"Articulation\", \"Rhythmic Complexity\", \"Rhythmic Stability\",  \"Dissonance\", \"Tonal Stability\", \"Modality\"]\n",
    "\n",
    "for i, count in enumerate(label_counts):\n",
    "    print(f\"{class_names[i] if i < len(class_names) else 'Class ' + str(i)}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = np.concatenate([mid_level_train_data, emotify_train_data], axis=0)\n",
    "combined_label = np.concatenate([mid_level_label_data, emotify_label_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "permutation = np.random.permutation(combined_train.shape[0]) # Randomly permute the indices using \"5000 + 400\"\n",
    "shuffled_train = combined_train[permutation]\n",
    "shuffled_label = combined_label[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final shapes to verify\n",
    "print(\"Shuffled Train Shape:\", shuffled_train.shape)\n",
    "print(\"Shuffled Label Shape:\", shuffled_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = np.sum(shuffled_label, axis=0)\n",
    "\n",
    "# Optional: class names if you have them\n",
    "class_names = [\"Melodiousness\", \"Articulation\", \"Rhythmic Complexity\", \"Rhythmic Stability\",  \"Dissonance\", \"Tonal Stability\", \"Modality\"]\n",
    "\n",
    "for i, count in enumerate(label_counts):\n",
    "    print(f\"{class_names[i] if i < len(class_names) else 'Class ' + str(i)}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train = shuffled_train[..., np.newaxis]  # Add a new axis to the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Shuffled Train Shape:\", shuffled_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid_level_train_data = mid_level_train_data[..., np.newaxis]\n",
    "\n",
    "# print(mid_level_train_data.shape, mid_level_train_data.dtype)  # Check the shape and type\n",
    "# print(mid_level_label_data.shape, mid_level_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotify_train_data = emotify_train_data[..., np.newaxis]\n",
    "\n",
    "# print(emotify_train_data.shape, emotify_train_data.dtype)  # Check the shape and type\n",
    "# print(emotify_label_data.shape, emotify_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid_level_input_shape = mid_level_train_data.shape[1], mid_level_train_data.shape[2], mid_level_train_data.shape[3]\n",
    "# emotify_input_shape = emotify_train_data.shape[1], emotify_train_data.shape[2], emotify_train_data.shape[3]\n",
    "# print(mid_level_input_shape, emotify_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tensorflow.device('/GPU:0'):\n",
    "#     input = Input(shape=(256, 1292, 1))\n",
    "#     x =  Conv2D(64, (5, 5), strides=2, activation=\"relu\", padding=\"valid\")(input)\n",
    "#     x =  BatchNormalization()(x)   \n",
    "#     # 2nd Layer\n",
    "#     x =  Conv2D(64, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 3rd Layer\n",
    "#     x =  MaxPooling2D((2, 2))(x)\n",
    "#     x =  Dropout(0.3)(x)    \n",
    "#     # 4th Layer\n",
    "#     x =  Conv2D(128, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 5th Layer\n",
    "#     x =  Conv2D(128, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 6th Layer\n",
    "#     x =  MaxPooling2D((2, 2))(x)\n",
    "#     x =  Dropout(0.3)(x)    \n",
    "#     # 7th Layer\n",
    "#     x =  Conv2D(256, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 8th Layer\n",
    "#     x =  Conv2D(256, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 9th Layer\n",
    "#     x =  Conv2D(384, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 10th Layer\n",
    "#     x =  Conv2D(512, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x)    \n",
    "#     # 11th Layer\n",
    "#     x =  Conv2D(256, (3, 3), strides=1, activation=\"relu\", padding=\"same\")(x)\n",
    "#     x =  BatchNormalization()(x) \n",
    "#     # 12th Layer\n",
    "#     # x = tfa.layers.AdaptiveAveragePooling2D(x)\n",
    "#     x =  GlobalAveragePooling2D(keepdims=True)(x)\n",
    "#     x =  Flatten()(x)\n",
    "#     x = keras.layers.Dense(256)(x)\n",
    "#     A2Mid2E_branch = keras.layers.Dense(7, activation=\"sigmoid\")(x)\n",
    "#     model = Model(inputs=input, outputs=A2Mid2E_branch, name=\"Mid-Level_Features\")\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model.keras\")\n",
    "model = load_model(\"fine-tuned_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.trainable:\n",
    "        print(layer.name, layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = GlobalAveragePooling2D(name=\"InsertedGlobalAveragePooling2D\")(model.layers[-5].output)\n",
    "# x = Dense(256, activation=\"relu\", name=\"InsertedDense2\")(x)\n",
    "# x = Dense(7, activation=\"sigmoid\", name=\"InsertedDense1\")(x)\n",
    "# model = Model(inputs=model.input, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers:\n",
    "    if layer.trainable:\n",
    "        print(layer.name, layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "model.compile(optimizer=Adam(learning_rate=3.1250e-05),\n",
    "                           loss='binary_crossentropy', metrics=[\"accuracy\"]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(mid_level_train_data, mid_level_label_data,\n",
    "model.fit(shuffled_train, shuffled_label,\n",
    "                       batch_size=8,\n",
    "                       epochs=5,\n",
    "                       shuffle=True, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
