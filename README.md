
# ğŸ§ **Mid-Level Perceptual Features Multi-Label Classification Model**

This multi-label classification model will be used to annotate the existing **Emotify dataset** with the goal of identifying the relationship or correlation between **emotional annotations** and **mid-level perceptual music features**.

---

## ğŸ“Š **Model Performance Overview**

- **Training Accuracy**: `0.7782`  
- **Training Loss**: `0.0018`  
- **Validation Accuracy**: `0.7840`  
- **Validation Loss**: `0.0016`  

---

## ğŸ“ˆ **Threshold-Based Evaluation (Macro Averaged Metrics)**

To evaluate the model's performance at different thresholds, the following metrics were calculated:

### **Threshold: 0.3**
- **Precision**: 0.9991  
- **Recall**: 0.9996  
- **F1 Score**: 0.9993  
- **Accuracy**: 0.9980  

### **Threshold: 0.4**
- **Precision**: 0.9992  
- **Recall**: 0.9996  
- **F1 Score**: 0.9994  
- **Accuracy**: 0.9984  

### **Threshold: 0.5**
- **Precision**: 0.9992  
- **Recall**: 0.9983  
- **F1 Score**: 0.9988  
- **Accuracy**: 0.9976  

### **Threshold: 0.6**
- **Precision**: 0.9992  
- **Recall**: 0.9983  
- **F1 Score**: 0.9988  
- **Accuracy**: 0.9976  
### VGG-style Network for Predicting Mid-Level Features from Audio

- **Based on the model by [Chowdhury et al.](https://arxiv.org/abs/1907.03572)**

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“  
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ     Param #   â”ƒ  
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©  
â”‚ input_layer (InputLayer)        â”‚ (None, 256, 1292, 1)   â”‚           0   â”‚  
â”‚ conv2d (Conv2D)                 â”‚ (None, 126, 644, 64)   â”‚       1,664   â”‚  
â”‚ batch_normalization             â”‚ (None, 126, 644, 64)   â”‚         256   â”‚  
â”‚ conv2d_1 (Conv2D)               â”‚ (None, 126, 644, 64)   â”‚      36,928   â”‚  
â”‚ batch_normalization_1           â”‚ (None, 126, 644, 64)   â”‚         256   â”‚  
â”‚ max_pooling2d (MaxPooling2D)    â”‚ (None, 63, 322, 64)    â”‚           0   â”‚  
â”‚ dropout (Dropout)               â”‚ (None, 63, 322, 64)    â”‚           0   â”‚  
â”‚ conv2d_2 (Conv2D)               â”‚ (None, 63, 322, 128)   â”‚      73,856   â”‚  
â”‚ batch_normalization_2           â”‚ (None, 63, 322, 128)   â”‚         512   â”‚  
â”‚ conv2d_3 (Conv2D)               â”‚ (None, 63, 322, 128)   â”‚     147,584   â”‚  
â”‚ batch_normalization_3           â”‚ (None, 63, 322, 128)   â”‚         512   â”‚  
â”‚ max_pooling2d_1 (MaxPooling2D)  â”‚ (None, 31, 161, 128)   â”‚           0   â”‚  
â”‚ dropout_1 (Dropout)             â”‚ (None, 31, 161, 128)   â”‚           0   â”‚  
â”‚ conv2d_4 (Conv2D)               â”‚ (None, 31, 161, 256)   â”‚     295,168   â”‚  
â”‚ batch_normalization_4           â”‚ (None, 31, 161, 256)   â”‚       1,024   â”‚  
â”‚ conv2d_5 (Conv2D)               â”‚ (None, 31, 161, 256)   â”‚     590,080   â”‚  
â”‚ batch_normalization_5           â”‚ (None, 31, 161, 256)   â”‚       1,024   â”‚  
â”‚ conv2d_6 (Conv2D)               â”‚ (None, 31, 161, 384)   â”‚     885,120   â”‚  
â”‚ batch_normalization_6           â”‚ (None, 31, 161, 384)   â”‚       1,536   â”‚  
â”‚ conv2d_7 (Conv2D)               â”‚ (None, 31, 161, 512)   â”‚   1,769,984   â”‚  
â”‚ batch_normalization_7           â”‚ (None, 31, 161, 512)   â”‚       2,048   â”‚  
â”‚ conv2d_8 (Conv2D)               â”‚ (None, 31, 161, 256)   â”‚   1,179,904   â”‚  
â”‚ batch_normalization_8           â”‚ (None, 31, 161, 256)   â”‚       1,024   â”‚  
â”‚ global_average_pooling2d        â”‚ (None, 1, 1, 256)      â”‚           0   â”‚  
â”‚ InsertedGlobalAveragePooling2D  â”‚ (None, 256)            â”‚           0   â”‚  
â”‚ InsertedDense2 (Dense)          â”‚ (None, 256)            â”‚      65,792   â”‚  
â”‚ InsertedDense1 (Dense)          â”‚ (None, 7)              â”‚       1,799   â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

> ğŸ› ï¸ **Note:**  
The final two Dense layers can be fine-tuned to adjust the model for different output dimensions or to improve performance on specific downstream tasks.
