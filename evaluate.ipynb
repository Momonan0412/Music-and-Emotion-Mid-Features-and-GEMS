{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547da90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 11:46:35.034496: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-26 11:46:35.253593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745639195.335074     783 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745639195.355936     783 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745639195.526341     783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745639195.526366     783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745639195.526367     783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745639195.526368     783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-26 11:46:35.545530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "import h5py\n",
    "import numpy as np\n",
    "import chowdhury_s_model_builder\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.api.models import Sequential, Model, load_model\n",
    "from keras.api.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, LSTM, Input, GlobalAveragePooling2D\n",
    "from keras.api.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502a45cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 256, 1292) float32\n",
      "(5000, 7) int8\n"
     ]
    }
   ],
   "source": [
    "# Open the HDF5 file in read mode\n",
    "with h5py.File(\"Data/Mid-Level_Perceptual_Features_Data.h5\", \"r\") as hf:\n",
    "    mid_level_train_data = hf[\"train\"][:]  # Load the train dataset\n",
    "    mid_level_label_data = hf[\"label\"][:]  # Load the label dataset\n",
    "\n",
    "print(mid_level_train_data.shape, mid_level_train_data.dtype)  # Check the shape and type\n",
    "print(mid_level_label_data.shape, mid_level_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319d74cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 256, 1292, 1) float32\n",
      "(5000, 7) int8\n"
     ]
    }
   ],
   "source": [
    "mid_level_train_data = mid_level_train_data[..., np.newaxis]\n",
    "\n",
    "print(mid_level_train_data.shape, mid_level_train_data.dtype)  # Check the shape and type\n",
    "print(mid_level_label_data.shape, mid_level_label_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e99ae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1292, 1)\n"
     ]
    }
   ],
   "source": [
    "mid_level_input_shape = mid_level_train_data.shape[1], mid_level_train_data.shape[2], mid_level_train_data.shape[3]\n",
    "print(mid_level_input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7544a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745639216.748275     783 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1745639216.751641     783 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1292</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">644</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">644</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">644</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">644</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">322</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,769,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InsertedGlobalAveragePooling2D  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InsertedDense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InsertedDense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1292\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m644\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m644\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m644\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m644\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m322\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m322\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m322\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m322\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m322\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m322\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m384\u001b[0m)   │       \u001b[38;5;34m885,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m384\u001b[0m)   │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m1,769,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m161\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InsertedGlobalAveragePooling2D  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InsertedDense2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ InsertedDense1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,191,255</span> (19.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,191,255\u001b[0m (19.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,591</span> (264.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,591\u001b[0m (264.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,988,480</span> (19.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,988,480\u001b[0m (19.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,184</span> (528.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m135,184\u001b[0m (528.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model(\"fine-tuned_model.keras\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5884a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
    "    mid_level_train_data, mid_level_label_data, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee8358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=3.1250e-05),\n",
    "                           loss='binary_crossentropy', metrics=[\"accuracy\"]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fce79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 129ms/step - accuracy: 0.7782 - loss: 0.0018\n",
      "Validation Loss: 0.0016471187118440866\n",
      "Validation Accuracy: 0.7839999794960022\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_val, y_val, batch_size=8, verbose=1)\n",
    "print(\"Validation Loss:\", results[0])\n",
    "print(\"Validation Accuracy:\", results[1])\n",
    "# Predict the labels for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbfdbc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 11:55:37.545836: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_275', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-04-26 11:55:41.257379: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:41.654403: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.396212375s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:43.552539: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:43.855884: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.303425258s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:44.856262: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=15,k6=0,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:47.145935: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.289755703s\n",
      "Trying algorithm eng33{k2=15,k6=0,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:51.882846: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng13{} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:53.655672: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.772942981s\n",
      "Trying algorithm eng13{} for conv %cudnn-conv-bias-activation.27 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,256,1292]{3,2,1,0} %bitcast.767, f32[64,1,5,5]{3,2,1,0} %bitcast.774, f32[64]{0} %bitcast.776), window={size=5x5 stride=2x2}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:54.981030: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:55:59.392008: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 5.411099135s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:00.392498: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:06.450165: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 7.05782521s\n",
      "Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:07.450515: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=2} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:09.884641: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.43421755s\n",
      "Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=2} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:12.087449: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:359] gpu_async_0 cuMemAllocAsync failed to allocate 3056140288 bytes: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      " Reported by CUDA: Free memory/Total memory: 0/4294443008\n",
      "2025-04-26 11:56:12.087593: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:364] Stats: Limit:                      1853253223\n",
      "InUse:                      5448311528\n",
      "MaxInUse:                   6794699512\n",
      "NumAllocs:                        2826\n",
      "MaxAllocSize:               3307520000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-04-26 11:56:12.087969: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:68] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2025-04-26 11:56:12.087990: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4, 288\n",
      "2025-04-26 11:56:12.087992: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8, 5\n",
      "2025-04-26 11:56:12.087993: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16, 2\n",
      "2025-04-26 11:56:12.087994: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 28, 1\n",
      "2025-04-26 11:56:12.087995: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 256, 10\n",
      "2025-04-26 11:56:12.087996: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 512, 10\n",
      "2025-04-26 11:56:12.087997: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1024, 16\n",
      "2025-04-26 11:56:12.087998: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1028, 1\n",
      "2025-04-26 11:56:12.087999: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1536, 5\n",
      "2025-04-26 11:56:12.087999: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2048, 5\n",
      "2025-04-26 11:56:12.088000: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 6400, 1\n",
      "2025-04-26 11:56:12.088001: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 7168, 1\n",
      "2025-04-26 11:56:12.088002: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 147456, 1\n",
      "2025-04-26 11:56:12.088003: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 262144, 1\n",
      "2025-04-26 11:56:12.088004: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 294912, 1\n",
      "2025-04-26 11:56:12.088005: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 589824, 1\n",
      "2025-04-26 11:56:12.088005: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1179648, 1\n",
      "2025-04-26 11:56:12.088006: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 2359296, 1\n",
      "2025-04-26 11:56:12.088007: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 3538944, 1\n",
      "2025-04-26 11:56:12.088008: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4718592, 1\n",
      "2025-04-26 11:56:12.088009: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 7077888, 1\n",
      "2025-04-26 11:56:12.088009: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16777472, 1\n",
      "2025-04-26 11:56:12.088010: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16924672, 1\n",
      "2025-04-26 11:56:12.088011: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 42336256, 1\n",
      "2025-04-26 11:56:12.088012: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 681508864, 3\n",
      "2025-04-26 11:56:12.088013: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 3307520000, 1\n",
      "2025-04-26 11:56:12.090677: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:104] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 5536481280\n",
      "2025-04-26 11:56:12.090707: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:106] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 5448311528\n",
      "2025-04-26 11:56:12.090709: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:107] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 6912212992\n",
      "2025-04-26 11:56:12.090711: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:108] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 6794699512\n",
      "2025-04-26 11:56:13.091883: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:21.081194: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 8.988217655s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:22.084802: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=3,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:24.285124: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.200355191s\n",
      "Trying algorithm eng11{k2=3,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:25.285582: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng13{} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:26.516150: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.230728482s\n",
      "Trying algorithm eng13{} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:27.516355: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:30.785760: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 4.269473344s\n",
      "Trying algorithm eng11{k2=4,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:34.052962: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:45.093390: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 14.307485886s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:46.093727: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng35{k2=2,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:48.854060: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.760375529s\n",
      "Trying algorithm eng35{k2=2,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:56:49.854315: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=15,k6=0,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:15.006067: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 26.151874369s\n",
      "Trying algorithm eng33{k2=15,k6=0,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:16.006484: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=0,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:19.124479: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 4.118162624s\n",
      "Trying algorithm eng11{k2=0,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:20.124707: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=4} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:22.139041: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.014417204s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=4} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:23.139349: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:25.655463: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.516251732s\n",
      "Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.28 = (f32[32,64,126,644]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,126,644]{3,2,1,0} %bitcast.802, f32[64,64,3,3]{3,2,1,0} %bitcast.809, f32[64]{0} %bitcast.811), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_1_2/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:26.904992: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=2} for conv %cudnn-conv-bias-activation.29 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,63,322]{3,2,1,0} %bitcast.840, f32[128,64,3,3]{3,2,1,0} %bitcast.847, f32[128]{0} %bitcast.849), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:27.166241: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.261473547s\n",
      "Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=2} for conv %cudnn-conv-bias-activation.29 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,63,322]{3,2,1,0} %bitcast.840, f32[128,64,3,3]{3,2,1,0} %bitcast.847, f32[128]{0} %bitcast.849), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:28.166652: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.29 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,63,322]{3,2,1,0} %bitcast.840, f32[128,64,3,3]{3,2,1,0} %bitcast.847, f32[128]{0} %bitcast.849), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:29.099487: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.932910872s\n",
      "Trying algorithm eng33{k2=2,k6=2,k13=1,k14=0,k22=0} for conv %cudnn-conv-bias-activation.29 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,63,322]{3,2,1,0} %bitcast.840, f32[128,64,3,3]{3,2,1,0} %bitcast.847, f32[128]{0} %bitcast.849), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:30.099979: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.29 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,63,322]{3,2,1,0} %bitcast.840, f32[128,64,3,3]{3,2,1,0} %bitcast.847, f32[128]{0} %bitcast.849), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:30.107480: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.00767726s\n",
      "Trying algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.29 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,63,322]{3,2,1,0} %bitcast.840, f32[128,64,3,3]{3,2,1,0} %bitcast.847, f32[128]{0} %bitcast.849), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_2_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:35.726179: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.30 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,63,322]{3,2,1,0} %bitcast.876, f32[128,128,3,3]{3,2,1,0} %bitcast.883, f32[128]{0} %bitcast.885), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_3_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:35.972471: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.246403544s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.30 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,63,322]{3,2,1,0} %bitcast.876, f32[128,128,3,3]{3,2,1,0} %bitcast.883, f32[128]{0} %bitcast.885), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_3_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:37.873122: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=4} for conv %cudnn-conv-bias-activation.30 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,63,322]{3,2,1,0} %bitcast.876, f32[128,128,3,3]{3,2,1,0} %bitcast.883, f32[128]{0} %bitcast.885), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_3_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:38.069742: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.196710193s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=4} for conv %cudnn-conv-bias-activation.30 = (f32[32,128,63,322]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,63,322]{3,2,1,0} %bitcast.876, f32[128,128,3,3]{3,2,1,0} %bitcast.883, f32[128]{0} %bitcast.885), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_3_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:44.902419: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.32 = (f32[32,256,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,31,161]{3,2,1,0} %bitcast.949, f32[256,256,3,3]{3,2,1,0} %bitcast.956, f32[256]{0} %bitcast.958), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_5_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:44.996073: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.092149366s\n",
      "Trying algorithm eng11{k2=1,k3=0} for conv %cudnn-conv-bias-activation.32 = (f32[32,256,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,31,161]{3,2,1,0} %bitcast.949, f32[256,256,3,3]{3,2,1,0} %bitcast.956, f32[256]{0} %bitcast.958), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_5_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:47.265406: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.33 = (f32[32,384,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,31,161]{3,2,1,0} %bitcast.985, f32[384,256,3,3]{3,2,1,0} %bitcast.992, f32[384]{0} %bitcast.994), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:48.726756: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.461560443s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.33 = (f32[32,384,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,256,31,161]{3,2,1,0} %bitcast.985, f32[384,256,3,3]{3,2,1,0} %bitcast.992, f32[384]{0} %bitcast.994), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_6_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:52.453941: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.34 = (f32[32,512,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,384,31,161]{3,2,1,0} %bitcast.1021, f32[512,384,3,3]{3,2,1,0} %bitcast.1028, f32[512]{0} %bitcast.1030), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_7_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:57:54.894327: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.440648891s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.34 = (f32[32,512,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,384,31,161]{3,2,1,0} %bitcast.1021, f32[512,384,3,3]{3,2,1,0} %bitcast.1028, f32[512]{0} %bitcast.1030), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_7_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:58:00.525396: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.35 = (f32[32,256,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,31,161]{3,2,1,0} %bitcast.1057, f32[256,512,3,3]{3,2,1,0} %bitcast.1064, f32[256]{0} %bitcast.1066), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:58:03.017129: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 3.491867013s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv %cudnn-conv-bias-activation.35 = (f32[32,256,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,31,161]{3,2,1,0} %bitcast.1057, f32[256,512,3,3]{3,2,1,0} %bitcast.1064, f32[256]{0} %bitcast.1066), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:58:04.392903: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=4} for conv %cudnn-conv-bias-activation.35 = (f32[32,256,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,31,161]{3,2,1,0} %bitcast.1057, f32[256,512,3,3]{3,2,1,0} %bitcast.1064, f32[256]{0} %bitcast.1066), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-26 11:58:05.517464: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.124648326s\n",
      "Trying algorithm eng15{k5=1,k6=0,k7=1,k10=4} for conv %cudnn-conv-bias-activation.35 = (f32[32,256,31,161]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,512,31,161]{3,2,1,0} %bitcast.1057, f32[256,512,3,3]{3,2,1,0} %bitcast.1064, f32[256]{0} %bitcast.1066), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1/conv2d_8_1/convolution\" source_file=\"/home/nigelchua0412/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 806ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 11:59:14.226030: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_275', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 887ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your trained model\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "# Convert probabilities to binary labels (e.g., threshold at 0.5)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe3e5dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           melody       1.00      1.00      1.00       680\n",
      "     articulation       1.00      1.00      1.00       449\n",
      "rhythm_complexity       1.00      0.99      1.00       132\n",
      " rhythm_stability       1.00      1.00      1.00       769\n",
      "       dissonance       1.00      1.00      1.00       213\n",
      "        atonality       1.00      1.00      1.00      1172\n",
      "             mode       1.00      1.00      1.00       410\n",
      "\n",
      "        micro avg       1.00      1.00      1.00      3825\n",
      "        macro avg       1.00      1.00      1.00      3825\n",
      "     weighted avg       1.00      1.00      1.00      3825\n",
      "      samples avg       1.00      1.00      1.00      3825\n",
      "\n",
      "Multilabel Confusion Matrix:\n",
      "[[[1820    0]\n",
      "  [   0  680]]\n",
      "\n",
      " [[2050    1]\n",
      "  [   0  449]]\n",
      "\n",
      " [[2368    0]\n",
      "  [   1  131]]\n",
      "\n",
      " [[1731    0]\n",
      "  [   2  767]]\n",
      "\n",
      " [[2287    0]\n",
      "  [   0  213]]\n",
      "\n",
      " [[1327    1]\n",
      "  [   2 1170]]\n",
      "\n",
      " [[2089    1]\n",
      "  [   0  410]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_names = ['melody', 'articulation', 'rhythm_complexity', 'rhythm_stability', 'dissonance', 'atonality', 'mode']\n",
    "# Generate the classification report\n",
    "report = classification_report(y_val, y_pred_binary, target_names=label_names)\n",
    "print(report)\n",
    "\n",
    "# Generate the multilabel confusion matrix\n",
    "mcm = multilabel_confusion_matrix(y_val, y_pred_binary)\n",
    "print(\"Multilabel Confusion Matrix:\")\n",
    "print(mcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "261e48de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for melody\n",
      "Actual [[1820    0]\n",
      " [   0  680]]\n",
      "Predicted\n",
      "Confusion Matrix for articulation\n",
      "Actual [[2050    1]\n",
      " [   0  449]]\n",
      "Predicted\n",
      "Confusion Matrix for rhythm_complexity\n",
      "Actual [[2368    0]\n",
      " [   1  131]]\n",
      "Predicted\n",
      "Confusion Matrix for rhythm_stability\n",
      "Actual [[1731    0]\n",
      " [   2  767]]\n",
      "Predicted\n",
      "Confusion Matrix for dissonance\n",
      "Actual [[2287    0]\n",
      " [   0  213]]\n",
      "Predicted\n",
      "Confusion Matrix for atonality\n",
      "Actual [[1327    1]\n",
      " [   2 1170]]\n",
      "Predicted\n",
      "Confusion Matrix for mode\n",
      "Actual [[2089    1]\n",
      " [   0  410]]\n",
      "Predicted\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define label names\n",
    "label_names = ['melody', 'articulation', 'rhythm_complexity', 'rhythm_stability', 'dissonance', 'atonality', 'mode']\n",
    "\n",
    "# Plot the confusion matrix for each label\n",
    "for i, cm in enumerate(mcm):\n",
    "    print(f'Confusion Matrix for {label_names[i]}')\n",
    "    print('Actual', cm)\n",
    "    print(\"Predicted\")\n",
    "    # plt.figure(figsize=(6, 4))\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "    # plt.title(f'Confusion Matrix for {label_names[i]}')\n",
    "    # plt.xlabel('Predicted')\n",
    "    # plt.ylabel('Actual')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3c1467f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               label  precision    recall  f1_score  accuracy\n",
      "0             melody   1.000000  1.000000  1.000000    1.0000\n",
      "1       articulation   0.997778  1.000000  0.998888    0.9996\n",
      "2  rhythm_complexity   1.000000  0.992424  0.996198    0.9996\n",
      "3   rhythm_stability   1.000000  0.997399  0.998698    0.9992\n",
      "4         dissonance   1.000000  1.000000  1.000000    1.0000\n",
      "5          atonality   0.999146  0.998294  0.998720    0.9988\n",
      "6               mode   0.997567  1.000000  0.998782    0.9996\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import ace_tools as tools\n",
    "# Define label names\n",
    "label_names = ['melody', 'articulation', 'rhythm_complexity', 'rhythm_stability', 'dissonance', 'atonality', 'mode']\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i, cm in enumerate(mcm):\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (tp + tn) / cm.sum()\n",
    "    metrics.append({\n",
    "        'label': label_names[i],\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "# Display metrics table\n",
    "print(df_metrics)\n",
    "# tools.display_dataframe_to_user(name=\"Label-wise Metrics\", dataframe=df_metrics)\n",
    "\n",
    "# # Plot all confusion matrices in a grid\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "# axes = axes.flatten()\n",
    "# for i, cm in enumerate(cms):\n",
    "#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#                 xticklabels=['Pred Neg', 'Pred Pos'],\n",
    "#                 yticklabels=['True Neg', 'True Pos'],\n",
    "#                 ax=axes[i])\n",
    "#     axes[i].set_title(label_names[i])\n",
    "#     axes[i].set_xlabel('Predicted')\n",
    "#     axes[i].set_ylabel('Actual')\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e865007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 482ms/step\n",
      "\n",
      "Threshold: 0.3\n",
      "  Precision: 0.9991\n",
      "  Recall:    0.9996\n",
      "  F1 Score:  0.9993\n",
      "  Accuracy:  0.9980\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 521ms/step\n",
      "\n",
      "Threshold: 0.4\n",
      "  Precision: 0.9992\n",
      "  Recall:    0.9996\n",
      "  F1 Score:  0.9994\n",
      "  Accuracy:  0.9984\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 595ms/step\n",
      "\n",
      "Threshold: 0.5\n",
      "  Precision: 0.9992\n",
      "  Recall:    0.9983\n",
      "  F1 Score:  0.9988\n",
      "  Accuracy:  0.9976\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 512ms/step\n",
      "\n",
      "Threshold: 0.6\n",
      "  Precision: 0.9992\n",
      "  Recall:    0.9983\n",
      "  F1 Score:  0.9988\n",
      "  Accuracy:  0.9976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "for t in thresholds:\n",
    "    preds = (model.predict(x_val) > t).astype(int)\n",
    "    precision = precision_score(y_val, preds, average='macro')\n",
    "    recall = recall_score(y_val, preds, average='macro')\n",
    "    f1 = f1_score(y_val, preds, average='macro')\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    print(f\"\\nThreshold: {t}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
